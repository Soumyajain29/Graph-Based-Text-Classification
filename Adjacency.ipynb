{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adjacency.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmxIYxg0gao2"
      },
      "source": [
        "!git clone https://github.com/deekshakoul/sent-conv-torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yBSCH_uklxo"
      },
      "source": [
        "!cp /content/sent-conv-torch/data/rt-polarity.all /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDXDG_zvllZ6"
      },
      "source": [
        "import os\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "import pickle as pkl\r\n",
        "from math import log\r\n",
        "import scipy.sparse as sp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f99mU7i9kqBQ"
      },
      "source": [
        "def create_df(filename):\r\n",
        "  with open(filename,'rb') as f: #MR\r\n",
        "    q = f.readlines()\r\n",
        "  texts=[]\r\n",
        "  for i in range(len(q)):\r\n",
        "    # print(i)\r\n",
        "    texts.append(q[i].decode('latin-1'))\r\n",
        "  ###################create dataframe##########################\r\n",
        "  df = pd.DataFrame(texts, columns=['text'])\r\n",
        "  df['label'] = df['text']\r\n",
        "  df['label'] =df['label'].apply(lambda s: s.split(\" \")[0])\r\n",
        "  df['text']=df['text'].apply(lambda s: s[1:])\r\n",
        "  df['label'] = df['label'].astype(int)\r\n",
        "  return df  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWHtzS3un4tW"
      },
      "source": [
        "f = 'rt-polarity.all'\r\n",
        "with open(f,'rb') as f:\r\n",
        "  q = f.readlines()\r\n",
        "\r\n",
        "texts=[]\r\n",
        "labels=[]\r\n",
        "for i in range(len(q)):\r\n",
        "  s = q[i].decode('latin-1')\r\n",
        "  texts.append(s[2:].strip())\r\n",
        "  labels.append(int(s[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plhRpkvJnvR7"
      },
      "source": [
        "word_set = set()\r\n",
        "word_freq = {}\r\n",
        "for doc in texts:\r\n",
        "  words_doc = doc.split()\r\n",
        "  for w in words_doc:\r\n",
        "    word_set.add(w)\r\n",
        "    if w in word_freq:\r\n",
        "      word_freq[w] += 1\r\n",
        "    else:\r\n",
        "      word_freq[w] = 1\r\n",
        "vocab = list(word_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMw0ZJ0FDtFY"
      },
      "source": [
        "map_word_index = {}\r\n",
        "for i in range(len(vocab)):\r\n",
        "  map_word_index[vocab[i]] = i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1mSg1TWrn-7"
      },
      "source": [
        "window =  20\r\n",
        "windows = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbGpkKeMsEft"
      },
      "source": [
        "#creating context windows for every document\r\n",
        "for doc in texts:\r\n",
        "  words = doc.split()\r\n",
        "  length = len(words)\r\n",
        "  if length <= window: #add all words if length of doc is less than context window size\r\n",
        "      windows.append(words)\r\n",
        "  else:\r\n",
        "    for j in range(length - window + 1):\r\n",
        "      window_ = words[j: j + window]\r\n",
        "      windows.append(window_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8bZoYlhMl55"
      },
      "source": [
        "word_window_freq = {}\r\n",
        "for window in windows:\r\n",
        "    appeared = set()\r\n",
        "    for i in range(len(window)):\r\n",
        "        if window[i] in appeared:\r\n",
        "            continue\r\n",
        "        if window[i] in word_window_freq:\r\n",
        "            word_window_freq[window[i]] += 1\r\n",
        "        else:\r\n",
        "            word_window_freq[window[i]] = 1\r\n",
        "        appeared.add(window[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtA4iTxntKJl"
      },
      "source": [
        "word_pair_count = {}\r\n",
        "#for every phrase in windows : make pairs of words  and take their count --> #W(i,j)\r\n",
        "for window in windows: #window: phrase under context size\r\n",
        "  for i in range(1, len(window)):\r\n",
        "    for j in range(0, i):\r\n",
        "      word_i = window[i]\r\n",
        "      word_i_id = map_word_index[word_i]\r\n",
        "      word_j = window[j]\r\n",
        "      word_j_id = map_word_index[word_j]\r\n",
        "    if word_i_id == word_j_id:\r\n",
        "      continue\r\n",
        "    word_pair_str = str(word_i_id) + ',' + str(word_j_id)\r\n",
        "    if word_pair_str in word_pair_count:\r\n",
        "      word_pair_count[word_pair_str] += 1\r\n",
        "    else:\r\n",
        "      word_pair_count[word_pair_str] = 1\r\n",
        "    word_pair_str = str(word_j_id) + ',' + str(word_i_id)\r\n",
        "    if word_pair_str in word_pair_count:\r\n",
        "      word_pair_count[word_pair_str] += 1\r\n",
        "    else:\r\n",
        "      word_pair_count[word_pair_str] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO9vYmvrEbFd"
      },
      "source": [
        "#PMI \r\n",
        "row = []\r\n",
        "col = []\r\n",
        "weight = []\r\n",
        "train_size = 0\r\n",
        "num_window = len(windows)\r\n",
        "\r\n",
        "for key in word_pair_count:\r\n",
        "    temp = key.split(',')\r\n",
        "    i = int(temp[0])\r\n",
        "    j = int(temp[1])\r\n",
        "    count = word_pair_count[key]\r\n",
        "    word_freq_i = word_window_freq[vocab[i]]\r\n",
        "    word_freq_j = word_window_freq[vocab[j]]\r\n",
        "    pmi = log((1.0 * count / num_window) /\r\n",
        "              (1.0 * word_freq_i * word_freq_j/(num_window * num_window)))\r\n",
        "    if pmi <= 0:\r\n",
        "        continue\r\n",
        "    row.append(train_size + i)\r\n",
        "    col.append(train_size + j)\r\n",
        "    weight.append(pmi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYhI8zs2NK9z"
      },
      "source": [
        "node_size = len(vocab)\r\n",
        "adj = sp.csr_matrix(\r\n",
        "    (weight, (row, col)), shape=(node_size, node_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqjvnXPrNtpo"
      },
      "source": [
        "dataset = 'MR'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AVI953BNXSf"
      },
      "source": [
        "with open(\"/content/{}.adj\".format(dataset), 'wb') as f:\r\n",
        "  pkl.dump(adj, f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}